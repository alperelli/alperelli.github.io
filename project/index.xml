<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Alessandro Perelli</title>
    <link>https://alperelli.github.io/project/</link>
      <atom:link href="https://alperelli.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 25 Jan 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://alperelli.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://alperelli.github.io/project/</link>
    </image>
    
    <item>
      <title>Convolutional Operator Learning for Imaging</title>
      <link>https://alperelli.github.io/project/mcaol_ct/</link>
      <pubDate>Tue, 25 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://alperelli.github.io/project/mcaol_ct/</guid>
      <description>&lt;p&gt;Data-driven and learning-based approaches have gained much interest in recent years for medical image reconstruction. These methods learn representations of images and are used in combination with model-based techniques to perform complex mappings between corrupted measurements and high-quality images.&lt;/p&gt;
&lt;p&gt;In this project, we develop a multi-channel convolutional analysis operator learning (MCAOL) framework that can exploit direct joint reconstruction, given the low-dose DECT measurements, where all the unknown
images are reconstructed simultaneously by solving one combined optimization problem.&lt;/p&gt;
&lt;p&gt;MCAOL requires considerably less memory compared to alternative DL approaches. The joint reconstruction approach is developed for a low-dose data acquisition protocol which consists of collecting data
using a sparse angular sampling, using a different X-ray energy in consecutive steps and low X-ray photon counts.
In Dual Energy CT (DECT), a reasonable prior assumption is that attenuation images at different
energies can be expected to be structurally similar in the sense that an edge (e.g., an organ boundary) that is present at one energy, is likely to be at same location and alignment with the other energies as well, even though the contrast between materials will be different at each energy.&lt;/p&gt;
&lt;p&gt;MCAOL technique reconstructs attenuation images from the projection data combined with multi-channel filters trained on a dataset of reconstructed images. The central idea of MCAOL is to learn unsupervised DECT muti-channel convolutional dictionaries that can provide a joint sparse representation of the underlined images by jointly learning filters for the different energies: each atom not only carries
individual information for each energy individually but also inter-energy information.
By reconstructing DECT images using MBIR techniques in conjunction with MCAOL, the multi-energy information can be optimally used by allowing the images to “talk to each other” during the reconstruction process through the learned joint dictionaries, reducing noise while preserving image resolution.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Regularized Stochastic Optimization by Denoising</title>
      <link>https://alperelli.github.io/project/red_spectral_ct/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://alperelli.github.io/project/red_spectral_ct/</guid>
      <description>&lt;p&gt;To solve the image reconstruction problem in the high-dimensional setting, numerous first order solvers which leverage random numerical linear algebra have been deployed in order to reduce the per-iteration computational cost in different machine learning and imaging applications. Well established algorithms like Stochastic Gradient Descent (SGD), order subsets and Alternating Direction Method of Multiplier (ADMM) have gained considerably attention in spectral CT [22, 23]. Unfortunately, the iteration complexity of first order methods relies significantly on the condition number of the problem like SGD which has a sub-linear convergence rate to only a neighborhood of the solution. Instead, the information related to the curvature is decisive to improve the convergence by reducing the condition number and to obtain physical meaningful and accurate quantitative estimation.&lt;/p&gt;
&lt;p&gt;Therefore, accounting for a greedy selection of parameters and step-size is crucial to design first-order algorithms for imaging like CT image reconstruction. Deterministic second order methods for solving regularized optimization problems with Generalized Linear Models (GLM) have been widely studied but despite the superior, linear or super-linear, convergence rate of Newton methods compared to first order methods one weakness relies on the high computational cost of calculating the Hessian matrix in high dimensional imaging application.&lt;/p&gt;
&lt;p&gt;In this project, a new family of second-order algorithm with application to statistical iterative material decomposition is developed which enjoys an improved accuracy and computation trade-off. We
propose a computational efficient quantitative estimation with second order and parameters-free methods based on randomized linear algebra and regularization induced by denoising. We exploit the recent development of randomized sketches and sub-sampling methods for the Hessian matrix to improve upon the computational cost-per-iteration.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Inference for Inverse Problems</title>
      <link>https://alperelli.github.io/project/amp_imaging/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://alperelli.github.io/project/amp_imaging/</guid>
      <description>&lt;p&gt;In order to accelerate the reconstruction, it is necessary to either design faster CT operators or develop iterative algorithms that can converge in fewer iterations.
In this project, we investigate the use of an emerging reconstruction method from Compressed Sensing (CS), called Approximate Message Passing (AMP), for sparse view CT reconstruction.&lt;/p&gt;
&lt;p&gt;AMP based inference refers to a family of iterative algorithms for Compressed Sensing problems with an i.i.d. random Gaussian system matrix and a sparse signal model. AMP is a form of approximate Bayesian inference based on the notion of message passing or loopy belief propagation and is also strongly connected to the family of Expectation Propagation and Expectation Consistent approximation algorithms.&lt;/p&gt;
&lt;p&gt;In essence, message passing algorithms work by iteratively updating marginal probabilities on
the unknown variables until a locally consistent posterior probability model is obtained. The
compelling aspect of the AMP family of algorithms is that they are designed to work in the
large system limit (for random systems) which enables the central limit theorem to be invoked.
This in turn simplifies the messages to be Gaussian distributions, requiring the algorithm to
only pass means and variances. The result is a very efficient algorithm that is remarkably
similar to the more traditional iterative shrinkage algorithm but with an additional Onsager
correction term. It also has many similarities to the Alternating Direction Method of
Multipliers (ADMM) algorithm.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
